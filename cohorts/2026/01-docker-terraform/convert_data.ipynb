{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e75ad616",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas pyarrow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3046af7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected file ../01-docker-terraform/data/green_tripdata_2020-01.parquet not found. Using first available parquet: ../01-docker-terraform/data/green_tripdata_2025-11.parquet\n",
      "Converted ../01-docker-terraform/data/green_tripdata_2025-11.parquet -> ../01-docker-terraform/data/green_tripdata_2025-11.csv using pyarrow (row-group streaming)\n",
      "Converted ../01-docker-terraform/data/green_tripdata_2025-11.parquet -> ../01-docker-terraform/data/green_tripdata_2025-11.csv using pyarrow (row-group streaming)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Paths (adjust if your data directory is different)\n",
    "input_path = Path('../01-docker-terraform/data/green_tripdata_2020-01.parquet')\n",
    "output_path = Path('../01-docker-terraform/data/green_tripdata.csv')\n",
    "\n",
    "# If the expected file doesn't exist, look for any .parquet in the data dir\n",
    "if not input_path.exists():\n",
    "    data_dir = input_path.parent\n",
    "    available = sorted([p for p in data_dir.iterdir() if p.suffix == '.parquet'])\n",
    "    if available:\n",
    "        print(f'Expected file {input_path} not found. Using first available parquet: {available[0]}')\n",
    "        input_path = available[0]\n",
    "        # adjust default output name to match chosen input file\n",
    "        output_path = data_dir / (input_path.stem + '.csv')\n",
    "    else:\n",
    "        raise FileNotFoundError(f'No parquet files found in {data_dir} - please place your parquet file there or update the path.')\n",
    "\n",
    "# Prefer pyarrow parquet streaming by row-group (lower memory).\n",
    "# Fall back to pandas.read_parquet if pyarrow is not available.\n",
    "try:\n",
    "    import pyarrow.parquet as pq\n",
    "    pf = pq.ParquetFile(str(input_path))\n",
    "    mode = 'w'\n",
    "    for rg in range(pf.num_row_groups):\n",
    "        table = pf.read_row_group(rg)\n",
    "        df = table.to_pandas()\n",
    "        # write header only for the first row-group\n",
    "        df.to_csv(output_path, index=False, mode=mode, header=(mode == 'w'))\n",
    "        mode = 'a'\n",
    "    print(f'Converted {input_path} -> {output_path} using pyarrow (row-group streaming)')\n",
    "except Exception as e:\n",
    "    print('pyarrow conversion failed or unavailable, falling back to pandas.read_parquet:', e)\n",
    "    # pandas will load the whole file into memory\n",
    "    df = pd.read_parquet(input_path)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f'Converted {input_path} -> {output_path} using pandas')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
